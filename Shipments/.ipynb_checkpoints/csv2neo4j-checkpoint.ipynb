{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:48:02.260895Z",
     "start_time": "2021-12-07T02:48:02.251312Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from py2neo import Graph, Node, NodeMatcher, Relationship\n",
    "from py2neo.matching import RelationshipMatcher\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "graph = Graph(host=\"192.168.195.207\", auth=(\"neo4j\", \"qwee\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:48:02.684315Z",
     "start_time": "2021-12-07T02:48:02.673155Z"
    }
   },
   "outputs": [],
   "source": [
    "# init graph database\n",
    "graph.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:48:03.230635Z",
     "start_time": "2021-12-07T02:48:03.147732Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path(\".\")\n",
    "sample_dir = root_dir / \"sample_data\"\n",
    "country_fp = sample_dir / \"country.csv\"\n",
    "export_sample_fp = sample_dir / \"export2020.csv\"\n",
    "import_sample_fp = sample_dir / \"import2020.csv\"\n",
    "exphscode_sample_fp = sample_dir / \"exphscode2020.csv\"\n",
    "imphscode_sample_fp = sample_dir / \"imphscode2020.csv\"\n",
    "\n",
    "country_df = pd.read_csv(country_fp, header=0)\n",
    "export_df = pd.read_csv(export_sample_fp, header=0)\n",
    "import_df = pd.read_csv(import_sample_fp, header=0)\n",
    "exphscode_df = pd.read_csv(exphscode_sample_fp, header=0)\n",
    "imphscode_df = pd.read_csv(imphscode_sample_fp, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:48:03.894020Z",
     "start_time": "2021-12-07T02:48:03.874756Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocessing missing country names\n",
    "# Trinidad and Tobago => Trinidad & Tobago\n",
    "# Virgin Islands (U.S.) => United States\n",
    "\n",
    "origins_list = [\"Trinidad and Tobago\", \"Virgin Islands (U.S.)\"]\n",
    "replaced_list = [\"Trinidad & Tobago\", \"United States\"]\n",
    "\n",
    "for orgn, rplc in zip(origins_list, replaced_list):\n",
    "    _idx = import_df[import_df[\"portofladingcountry\"] == orgn].index\n",
    "    import_df.loc[_idx, \"portofladingcountry\"] = rplc\n",
    "\n",
    "    _idx = export_df[export_df[\"portOfLadingCountry\"] == orgn].index\n",
    "    export_df.loc[_idx, \"portOfLadingCountry\"] = rplc\n",
    "\n",
    "    _idx = export_df[export_df[\"portofUnladingCountry\"] == orgn].index\n",
    "    export_df.loc[_idx, \"portofUnladingCountry\"] = rplc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:48:05.719084Z",
     "start_time": "2021-12-07T02:48:05.714001Z"
    }
   },
   "outputs": [],
   "source": [
    "# definations of nodes\n",
    "N_INC = \"Incorporation\"\n",
    "N_COUN = \"Country\"\n",
    "N_PORT = \"Port\"\n",
    "N_GOOD = \"Goods\"\n",
    "\n",
    "\n",
    "# definations of relationships\n",
    "R_IMP = \"Import\"\n",
    "R_EXP = \"Export\"\n",
    "\n",
    "R_BEL = \"Belong\"\n",
    "R_LAD = \"Lading\"\n",
    "R_CONS = \"Consign\"\n",
    "R_TRAN = \"Transport\"\n",
    "R_BUY = \"Buy\"\n",
    "R_SELL = \"Sell\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nodes: country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:48:08.250601Z",
     "start_time": "2021-12-07T02:48:07.246605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833b8ab25956404c852b1d644a5195b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "set_country_node..:   0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating nodes: country\n",
    "\n",
    "def set_country_node_func(row):\n",
    "    _p = Node(\n",
    "        N_COUN,\n",
    "        name=row.country,\n",
    "        countryid=row.countryId,\n",
    "        iso2=row.iso2,\n",
    "        iso3=row.iso3,\n",
    "        regionid=row.regionid,\n",
    "        region=row.region,\n",
    "    )\n",
    "    graph.create(_p)\n",
    "\n",
    "tqdm.pandas(desc=\"set_country_node..\")\n",
    "_r = country_df.progress_apply(set_country_node_func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nodes: port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:48:12.345074Z",
     "start_time": "2021-12-07T02:48:09.842677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369207f872144080bb62851ee3f25ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "set_port_node..:   0%|          | 0/251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating nodes: port\n",
    "# and set the rationship between port and country\n",
    "\n",
    "port_exp_df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": list(export_df[\"portOfLading\"]) + list(export_df[\"portOfUnlading\"]),\n",
    "        \"region\": list(export_df[\"portOfLadingRegion\"])\n",
    "        + list(export_df[\"portOfUnladingRegion\"]),\n",
    "        \"country\": list(export_df[\"portOfLadingCountry\"])\n",
    "        + list(export_df[\"portofUnladingCountry\"]),\n",
    "    }\n",
    ")\n",
    "\n",
    "# the import_df has no coloum of portofUnladingCountry, so append it\n",
    "import_df[\"portofunladingcountry\"] = \"United States\"\n",
    "port_imp_df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": list(import_df[\"portoflading\"]) + list(import_df[\"portofunlading\"]),\n",
    "        \"region\": list(import_df[\"portofladingregion\"])\n",
    "        + list(import_df[\"portofunladingregion\"]),\n",
    "        \"country\": list(import_df[\"portofladingcountry\"])\n",
    "        + list(import_df[\"portofunladingcountry\"]),\n",
    "    }\n",
    ")\n",
    "\n",
    "port_df = (\n",
    "    pd.concat([port_exp_df, port_imp_df], axis=0)\n",
    "    .dropna(subset=[\"name\", \"country\"])\n",
    "    .drop_duplicates()\n",
    ")\n",
    "mather = NodeMatcher(graph)\n",
    "\n",
    "\n",
    "def set_port_node_func(row):\n",
    "    _port = Node(N_PORT, name=row[\"name\"], region=row.region)\n",
    "    graph.create(_port)\n",
    "    _country = mather.match(N_COUN, name=row.country).first()\n",
    "    # if the country is not in the list of nodes\n",
    "    try:\n",
    "        # belong relationship\n",
    "        _r = Relationship(_port, R_BEL, _country)\n",
    "        graph.create(_r)\n",
    "    except Exception as ex:\n",
    "        print(row)\n",
    "        print(ex)\n",
    "\n",
    "\n",
    "tqdm.pandas(desc=\"set_port_node..\")\n",
    "_r = port_df.progress_apply(set_port_node_func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nodes: inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:48:22.843409Z",
     "start_time": "2021-12-07T02:48:14.455650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03da2efee85413f9ad7eacf75661206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "set_inc_node..:   0%|          | 0/1889 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating nodes: inc\n",
    "\n",
    "# list all incs in export file\n",
    "# only shipper inc. included in export file\n",
    "inc_exp_columns = [\n",
    "    \"shpName\",\n",
    "    \"shpFullAddress\",\n",
    "    \"shpRoute\",\n",
    "    \"shpPanjivaId\",\n",
    "    \"shpCity\",\n",
    "    \"shpStateRegion\",\n",
    "    \"shpPostalCode\",\n",
    "    \"shpOriginalFormat\",\n",
    "]\n",
    "\n",
    "inc_exp_df = export_df[inc_exp_columns]\n",
    "\n",
    "# list all incs in import file\n",
    "# both shipper inc and consignee inc included in import file\n",
    "inc_imp_columns = [\n",
    "    \"conname\",\n",
    "    \"confulladdress\",\n",
    "    \"conroute\",\n",
    "    \"conoriginalformat\",\n",
    "    \"concity\",\n",
    "    \"constateregion\",\n",
    "    \"conpostalcode\",\n",
    "    \"conpanjivaid\",\n",
    "    \"shpname\",\n",
    "    \"shpfulladdress\",\n",
    "    \"shproute\",\n",
    "    \"shpcity\",\n",
    "    \"shpstateregion\",\n",
    "    \"shppostalcode\",\n",
    "    \"shppanjivaid\",\n",
    "    \"shporiginalformat\",\n",
    "]\n",
    "inc_imp_df = pd.DataFrame(\n",
    "{\n",
    "        \"name\": list(import_df[\"shpname\"]) + list(import_df[\"conname\"]),\n",
    "        \"fulladdress\": list(import_df[\"shpfulladdress\"])\n",
    "        + list(import_df[\"confulladdress\"]),\n",
    "        \"route\": list(import_df[\"shproute\"]) + list(import_df[\"conroute\"]),\n",
    "        \"originalformat\": list(import_df[\"shporiginalformat\"])\n",
    "        + list(import_df[\"conoriginalformat\"]),\n",
    "        \"city\": list(import_df[\"shpcity\"]) + list(import_df[\"concity\"]),\n",
    "        \"stateregion\": list(import_df[\"shpstateregion\"])\n",
    "        + list(import_df[\"constateregion\"]),\n",
    "        \"postalcode\": list(import_df[\"shppostalcode\"])\n",
    "        + list(import_df[\"conpostalcode\"]),\n",
    "        \"panjivaid\": list(import_df[\"shppanjivaid\"])\n",
    "        + list(import_df[\"conpanjivaid\"]),\n",
    "})\n",
    "\n",
    "# integrate both incs in export file and import file\n",
    "# drop the duplicated incs and nan rows\n",
    "inc_df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": list(inc_exp_df[\"shpName\"]) + list(inc_imp_df[\"name\"]),\n",
    "        \"fulladdress\": list(inc_exp_df[\"shpFullAddress\"])\n",
    "        + list(inc_imp_df[\"fulladdress\"]),\n",
    "        \"route\": list(inc_exp_df[\"shpRoute\"]) + list(inc_imp_df[\"route\"]),\n",
    "        \"originalformat\": list(inc_exp_df[\"shpOriginalFormat\"])\n",
    "        + list(inc_imp_df[\"originalformat\"]),\n",
    "        \"city\": list(inc_exp_df[\"shpCity\"]) + list(inc_imp_df[\"city\"]),\n",
    "        \"stateregion\": list(inc_exp_df[\"shpStateRegion\"])\n",
    "        + list(inc_imp_df[\"stateregion\"]),\n",
    "        \"postalcode\": list(inc_exp_df[\"shpPostalCode\"])\n",
    "        + list(inc_imp_df[\"postalcode\"]),\n",
    "        \"panjivaid\": list(inc_exp_df[\"shpPanjivaId\"])\n",
    "        + list(inc_imp_df[\"panjivaid\"]),\n",
    "    }\n",
    ").dropna(subset=(\"name\", \"panjivaid\")).drop_duplicates()\n",
    "\n",
    "def set_inc_node_func(row):\n",
    "    _inc = Node(\n",
    "        N_INC,\n",
    "        name=row[\"name\"],\n",
    "        fulladdress=row.fulladdress,\n",
    "        route=row.route,\n",
    "        originalformat=row.originalformat,\n",
    "        city=row.city,\n",
    "        stateregion=row.stateregion,\n",
    "        postalcode=row.postalcode,\n",
    "        panjivaid=row.panjivaid,\n",
    "    )\n",
    "    graph.create(_inc)\n",
    "\n",
    "tqdm.pandas(desc=\"set_inc_node..\")\n",
    "_r = inc_df.progress_apply(set_inc_node_func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nodes: goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:48:27.517883Z",
     "start_time": "2021-12-07T02:48:24.967944Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating node: goods\n",
    "\n",
    "import re\n",
    "def split_hscode_func(row):\n",
    "    hs_code_str = row['hsCode']\n",
    "    splited_list = str(hs_code_str).split(';')\n",
    "    if len(splited_list) == 0: # no any codes\n",
    "        return []\n",
    "    else:\n",
    "        hscode_return_list = []\n",
    "        for _str in splited_list:\n",
    "            if len(_str) > 5: # except irregular chars: such as '', '\\n', '[]'\n",
    "                try:\n",
    "                    _result = re.findall(r'(\\d{4}\\.\\d{2}|\\d{6})',_str)[0]\n",
    "                except Exception as ex:\n",
    "                    print(ex)\n",
    "                    print(_str)\n",
    "                    break\n",
    "                if _result.find('.') == -1:\n",
    "                    hscode_return_list.append(_result)\n",
    "                else:\n",
    "                    _result = ''.join(_result.split('.'))\n",
    "                    hscode_return_list.append(_result)\n",
    "        return hscode_return_list\n",
    "\n",
    "exphscode_df['hs_code_list'] = exphscode_df.apply(split_hscode_func, axis=1)\n",
    "imphscode_df['hs_code_list'] = imphscode_df.apply(split_hscode_func, axis=1)\n",
    "\n",
    "all_hscodes = []\n",
    "for hs_code_list in list(exphscode_df['hs_code_list'])+list(imphscode_df['hs_code_list']):\n",
    "    all_hscodes.extend(hs_code_list)\n",
    "\n",
    "tqdm.pandas(desc=\"set_goods_node..\")\n",
    "for hscode in tqdm(list(set(all_hscodes))):\n",
    "    _hscode = Node(N_GOOD, name=hscode)\n",
    "    graph.create(_hscode)\n",
    "\n",
    "# create a specical Goods Node for no hscode in recording\n",
    "_hscode_NaN = Node(N_GOOD, name='NaN')\n",
    "graph.create(_hscode_NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relationship: import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T02:58:50.184709Z",
     "start_time": "2021-12-07T02:58:21.100895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abee1dd691c49c186976bb6d9387bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "set_import_relationship..:   0%|          | 0/677 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating relationship: import\n",
    "\n",
    "# a dictionary maping recordid to hscode\n",
    "imp_recordid2hscode_dict = {}\n",
    "for row in imphscode_df[[\"panjivaRecordId\", \"hs_code_list\"]].itertuples():\n",
    "    rcd, hsc = getattr(row, \"panjivaRecordId\"), getattr(row, \"hs_code_list\")\n",
    "    imp_recordid2hscode_dict[rcd] = hsc\n",
    "\n",
    "mather = NodeMatcher(graph)\n",
    "\n",
    "def set_imp_func(row):\n",
    "    # import relationship between countries\n",
    "    _ladingcountry = mather.match(N_COUN, name=row.portofladingcountry).first()\n",
    "    _unladingcountry = mather.match(N_COUN, name=row.portofunladingcountry).first()\n",
    "    try:\n",
    "        _imp = Relationship(\n",
    "            _unladingcountry, R_IMP, _ladingcountry,\n",
    "            panjivarecordid=row.panjivarecordid,\n",
    "            billofladingnumber=row.billofladingnumber,\n",
    "            hscode=imp_recordid2hscode_dict.get(row.panjivarecordid),\n",
    "            date=row.arrivaldate,\n",
    "            vessel=row.vessel,\n",
    "            volumeteu=row.volumeteu,\n",
    "            quantity=row.quantity,\n",
    "            measurement=row.measurement,\n",
    "            weightkg=row.weightkg,\n",
    "        )\n",
    "        graph.create(_imp)\n",
    "    except Exception as ex:\n",
    "        print('import err: {}, {}'.format(row.portofladingcountry, row.portofunladingcountry))\n",
    "        print(ex)\n",
    "    \n",
    "    # consign relationship between inc and port\n",
    "    _portofunlading = mather.match(N_PORT, name=row.portofunlading).first()\n",
    "    _consign_inc = mather.match(N_INC, name=row.conname).first()\n",
    "    try:\n",
    "        _consign = Relationship(_portofunlading, R_CONS, _consign_inc,\n",
    "                                panjivarecordid=row.panjivarecordid, \n",
    "                                date=row.arrivaldate,)\n",
    "        graph.create(_consign)\n",
    "    except Exception as ex:\n",
    "        print('consign err: {}, {}'.format(row.portofunlading, row.conname))\n",
    "        print(ex)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ladding relationship between inc and port\n",
    "    _portoflading = mather.match(N_PORT, name=row.portoflading).first()\n",
    "    _shipper_inc = mather.match(N_INC, name=row.shpname).first()\n",
    "    try:\n",
    "        _ladding = Relationship(_shipper_inc, R_LAD, _portoflading, \n",
    "                               panjivarecordid=row.panjivarecordid, \n",
    "                                date=row.arrivaldate,)\n",
    "        graph.create(_ladding)\n",
    "    except Exception as ex:\n",
    "        print('ladding err: {}, {}'.format(row.portoflading, row.shpname))\n",
    "        print(ex)\n",
    "    \n",
    "    \n",
    "    # transport relationship between port\n",
    "    _transport = Relationship(\n",
    "        _portoflading,\n",
    "        R_TRAN,\n",
    "        _portofunlading,\n",
    "        panjivarecordid=row.panjivarecordid,\n",
    "        date=row.arrivaldate,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # import relationship between inc.\n",
    "    _imp = Relationship(\n",
    "        _consign_inc, R_IMP, _shipper_inc,\n",
    "        panjivarecordid=row.panjivarecordid,\n",
    "        billofladingnumber=row.billofladingnumber,\n",
    "        hscode=imp_recordid2hscode_dict.get(row.panjivarecordid),\n",
    "        date=row.arrivaldate,\n",
    "        vessel=row.vessel,\n",
    "        volumeteu=row.volumeteu,\n",
    "        quantity=row.quantity,\n",
    "        measurement=row.measurement,\n",
    "        weightkg=row.weightkg,\n",
    "    )\n",
    "    graph.create(_imp)\n",
    "    \n",
    "    # buy/sell relationship between inc. and goods\n",
    "    hscodes = imp_recordid2hscode_dict.get(row.panjivarecordid)\n",
    "    if not hscodes: \n",
    "        _goods = mather.match(N_GOOD, name='NaN').first()\n",
    "        _buy = Relationship(_consign_inc, R_BUY, _goods,\n",
    "                            panjivarecordid=row.panjivarecordid, \n",
    "                            date=row.arrivaldate,)\n",
    "        _sell = Relationship(_shipper_inc, R_SELL, _goods,\n",
    "                            panjivarecordid=row.panjivarecordid, \n",
    "                            date=row.arrivaldate,)\n",
    "        graph.create(_buy)\n",
    "        graph.create(_sell)\n",
    "    else:\n",
    "        for hscode in hscodes:\n",
    "            _goods = mather.match(N_GOOD, name=hscode).first()\n",
    "            _buy = Relationship(_consign_inc, R_BUY, _goods,\n",
    "                                panjivarecordid=row.panjivarecordid, \n",
    "                                date=row.arrivaldate,)\n",
    "            _sell = Relationship(_shipper_inc, R_SELL, _goods,\n",
    "                                panjivarecordid=row.panjivarecordid, \n",
    "                                date=row.arrivaldate,)\n",
    "            graph.create(_buy)\n",
    "            graph.create(_sell)\n",
    "            \n",
    "\n",
    "tqdm.pandas(desc=\"set_import_relationship..\")\n",
    "_r = import_df.dropna(subset=['portofladingcountry', 'portofunladingcountry', 'panjivarecordid',\n",
    "                             'portofunlading', 'portoflading', 'shpname', 'conname']) \\\n",
    "              .progress_apply(set_imp_func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relationship: export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669ac3be6713481389b8662d3e5a4a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "set_export_relationship..:   0%|          | 0/797 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating relationship: export\n",
    "# a dictionary maping recordid to hscode\n",
    "exp_recordid2hscode_dict = {}\n",
    "for row in exphscode_df[[\"panjivaRecordId\", \"hs_code_list\"]].itertuples():\n",
    "    rcd, hsc = getattr(row, \"panjivaRecordId\"), getattr(row, \"hs_code_list\")\n",
    "    exp_recordid2hscode_dict[rcd] = hsc\n",
    "\n",
    "mather = NodeMatcher(graph)\n",
    "\n",
    "\n",
    "def set_exp_func(row):\n",
    "    # export relationship between countries\n",
    "    _ladingcountry = mather.match(N_COUN, name=row.portOfLadingCountry).first()\n",
    "    _unladingcountry = mather.match(N_COUN, name=row.portofUnladingCountry).first()\n",
    "    try:\n",
    "        _imp = Relationship(\n",
    "            _ladingcountry,\n",
    "            R_EXP,\n",
    "            _unladingcountry,\n",
    "            panjivarecordid=row.panjivarecordid,\n",
    "            billofladingnumber=row.billOfLadingNumber,\n",
    "            hscode=imp_recordid2hscode_dict.get(row.panjivarecordid),\n",
    "            date=row.shpmtDate,\n",
    "            vessel=row.vessel,\n",
    "            volumeteu=row.volumeTEU,\n",
    "            weightkg=row.weightkg,\n",
    "        )\n",
    "        graph.create(_imp)\n",
    "    except Exception as ex:\n",
    "        print(\n",
    "            \"export err: {}, {}\".format(\n",
    "                row.portOfLadingCountry, row.portofUnladingCountry\n",
    "            )\n",
    "        )\n",
    "        print(ex)\n",
    "\n",
    "    # consign relationship between inc and port\n",
    "    # consignee (Inc.) information in export file is unavailable\n",
    "\n",
    "    # ladding relationship between inc and port\n",
    "    _portoflading = mather.match(N_PORT, name=row.portOfLading).first()\n",
    "    _shipper_inc = mather.match(N_INC, name=row.shpName).first()\n",
    "    try:\n",
    "        _ladding = Relationship(\n",
    "            _shipper_inc,\n",
    "            R_LAD,\n",
    "            _portoflading,\n",
    "            panjivarecordid=row.panjivarecordid,\n",
    "            date=row.shpmtDate,\n",
    "        )\n",
    "        graph.create(_ladding)\n",
    "    except Exception as ex:\n",
    "        print(\"ladding err: {}, {}\".format(row.portOfLading, row.shpName))\n",
    "        print(ex)\n",
    "\n",
    "    # transport relationship between port\n",
    "    _portofunlading = mather.match(N_PORT, name=row.portOfUnlading).first()\n",
    "    _transport = Relationship(\n",
    "        _portoflading,\n",
    "        R_TRAN,\n",
    "        _portofunlading,\n",
    "        panjivarecordid=row.panjivarecordid,\n",
    "        date=row.shpmtDate,\n",
    "    )\n",
    "\n",
    "    # sell relationship between inc. and goods\n",
    "    hscodes = exp_recordid2hscode_dict.get(row.panjivarecordid)\n",
    "    if not hscodes:\n",
    "        _goods = mather.match(N_GOOD, name=\"NaN\").first()\n",
    "        _sell = Relationship(\n",
    "            _shipper_inc,\n",
    "            R_SELL,\n",
    "            _goods,\n",
    "            panjivarecordid=row.panjivarecordid,\n",
    "            date=row.shpmtDate,\n",
    "        )\n",
    "        graph.create(_sell)\n",
    "    else:\n",
    "        for hscode in hscodes:\n",
    "            _goods = mather.match(N_GOOD, name=hscode).first()\n",
    "            _sell = Relationship(\n",
    "                _shipper_inc,\n",
    "                R_SELL,\n",
    "                _goods,\n",
    "                panjivarecordid=row.panjivarecordid,\n",
    "                date=row.shpmtDate,\n",
    "            )\n",
    "            graph.create(_sell)\n",
    "\n",
    "\n",
    "tqdm.pandas(desc=\"set_export_relationship..\")\n",
    "_r = export_df.dropna(\n",
    "    subset=[\n",
    "        \"portOfLadingCountry\",\n",
    "        \"portofUnladingCountry\",\n",
    "        \"panjivarecordid\",\n",
    "        \"portOfLading\",\n",
    "        \"portOfUnlading\",\n",
    "        \"shpName\",\n",
    "    ]\n",
    ").progress_apply(set_exp_func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Export(Node('Country', country_id=213, iso2='US', iso3='USA', name='United States', region='United States and Canada', region_id=10359.0), Node('Country', country_id=46, iso2='CO', iso3='COL', name='Colombia', region='Latin America and Caribbean', region_id=10360.0), billofladingnumber='SUDU29001AKXMZ55', panjivarecordid=32695761, shipmentdate='2020-01-01', vessel='Monte Verde', volumeteu=2.0, weightkg=21732.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_matcher = NodeMatcher(graph)\n",
    "relation_matcher = RelationshipMatcher(graph)\n",
    "\n",
    "_node1 = node_matcher.match(N_COUN, name=\"Colombia\").first()\n",
    "_node2 = node_matcher.match(N_COUN, name=\"United States\").first()\n",
    "ret = relation_matcher.match((_node2, _node1), r_type=R_EXP).first()\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Import(Node('Country', country_id=213, iso2='US', iso3='USA', name='United States', region='United States and Canada', region_id=10359.0), Node('Country', country_id=46, iso2='CO', iso3='COL', name='Colombia', region='Latin America and Caribbean', region_id=10360.0), arrivaldate='2020-01-01', billofladingnumber='HLCUSS5191085901', hscode=21451469, measurement=nan, panjivarecordid=184108255, quantity='504 PCS', vessel='NYK ROMULUS', volumeteu=2.0, weightkg=17204.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_node1 = node_matcher.match(N_COUN, name=\"Colombia\").first()\n",
    "_node2 = node_matcher.match(N_COUN, name=\"United States\").first()\n",
    "ret = relation_matcher.match((_node2, _node1), r_type=R_IMP).first()\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daily use py3.6",
   "language": "python",
   "name": "daily-py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
